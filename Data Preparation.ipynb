{"cells": [{"metadata": {}, "id": "401910bc", "cell_type": "markdown", "source": "# Hands-on: Data Preparation\n\n## Overview\n\nIn this hands-on activity, you will import your dataset (a CSV file) into a notebook to prepare the data. The objective is to guarantee the data quality by pre-processing the raw data before it is utilized in analytics or used as ML model's training dataset.\n\nYou will learn about:\n1. Process null columns \n2. Process duplicated rows\n3. Process outliers\n4. Derive new columns \n5. Save cleansed data as new CSV\n\nSample data: https://ibm.box.com/v/hotel-bookings-sample-dataset\n\nOriginal data source: \nhttps://www.sciencedirect.com/science/article/pii/S2352340918315191\nhttps://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand"}, {"metadata": {}, "id": "ed725334", "cell_type": "markdown", "source": "## Setup"}, {"metadata": {}, "id": "e3e5401d", "cell_type": "code", "source": "# Import library\nimport pandas as pd\nimport numpy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\npd.set_option('display.max_columns', None)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "0c7c4262", "cell_type": "markdown", "source": "## Load Data\n- Replace this part with your own code. To insert Code Snippet for Data Ingestion, click '</>' icon located in the top-right menu."}, {"metadata": {}, "id": "43c4e742", "cell_type": "code", "source": "# Replace this part with your own code\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='PjXGOLvd9BTXHT3f_wi2ujiwywR5hnfK7tAJkfmahpxu',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us-south.cloud-object-storage.appdomain.cloud')\n\nbucket = 'mlpredictivemodel-donotdelete-pr-se3ulnjuojrkgg'\nobject_key = 'hotel_bookings.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head(10)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "ba24eab0", "cell_type": "code", "source": "# Show number of columns and rows\ndf.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a72a61be", "cell_type": "code", "source": "# Show all columns name\ndf.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "11ce18fd", "cell_type": "code", "source": "# Show reservation status unique values\ndf['reservation_status'].unique()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "e7ca0da0", "cell_type": "markdown", "source": "## 1. Process Null Columns"}, {"metadata": {}, "id": "ead9bc9e", "cell_type": "code", "source": "# Check null\ndf.isna().sum()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "60707679", "cell_type": "code", "source": "# Check columns with null\nfeatures = ['children', 'country', 'agent', 'company']\n\nfor feat in features:\n    perc = len(df[df[feat].isna()])/len(df)*100\n    perc = round(perc, 1)\n    print(f'Null in {feat}:', perc, '%')\n    print(df[feat].describe(), '\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "7469b626", "cell_type": "code", "source": "# For 'children', impute the null with median value\nif df['children'].notna().any():\n    mode = df['children'].mode()[0]\n    df['children'].fillna(value=mode, inplace=True)\n    \n# For 'country', impute the null with most frequent value\nif df['country'].notna().any():\n    mode = df['country'].mode()[0]\n    df['country'].fillna(value=mode, inplace=True)\n\n# For 'agent', impute the null with most frequent value\nif df['agent'].notna().any():\n    mode = df['agent'].mode()[0]\n    df['agent'].fillna(value=mode, inplace=True)\n    \n# For 'company', drop the column due to large number of null\ndf.drop('company', axis=1, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "86234f92", "cell_type": "markdown", "source": "## 2. Process Duplicated Rows"}, {"metadata": {}, "id": "f61051fb", "cell_type": "code", "source": "# Check duplicated data\ndf[df.duplicated()] \n# -> Since there is no unique reservations ID and the duplicated number of rows is significant, keep the data.", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "e0cad21d", "cell_type": "markdown", "source": "## 3. Process Outliers"}, {"metadata": {}, "id": "64839083", "cell_type": "code", "source": "# Check outliers in original data\ndf_describe = pd.DataFrame(df.describe(include='all'))\ndf_describe", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "3d02cda3", "cell_type": "code", "source": "# Process outliers in original data\n\n# Impute outlier value with 0\ndf.loc[df['adults']>4, 'adults'] = 0\ndf.loc[df['children']>4, 'children'] = 0\ndf.loc[df['babies']>4, 'babies'] = 0\n\n# 'Meal' contains values \"Undefined\", which is equal to SC\ndf['meal'].replace('Undefined', 'SC', inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "7553a162", "cell_type": "markdown", "source": "## 4. Derive New Columns"}, {"metadata": {}, "id": "8ce85b68", "cell_type": "code", "source": "# Derive new columns\n\n# Create 'total_stay_nights'\ndf['total_stay_nights'] = df['stays_in_week_nights'] + df['stays_in_weekend_nights']\n\n# Create 'kids'& 'num_pax'\ndf['kids'] = df['children'] + df['babies'] \ndf['num_pax'] = df['adults'] + df['kids'] ", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a3f3893d", "cell_type": "code", "source": "# Check outliers in derived data\ndf_der = pd.DataFrame(df[['total_stay_nights', 'num_pax']].describe())\ndf_der", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a83c6fff", "cell_type": "code", "source": "print(df[df['num_pax']==0].shape)\n# Drop the rows if 'num_pax' == 0\ndf = df[df['num_pax']!=0]\ndf.shape\n# -> Remove the rows since there is no data about pax and the row number is not significant", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "7442ece9", "cell_type": "markdown", "source": "## 5. Save Cleansed Data as New CSV"}, {"metadata": {}, "id": "c5e83b46", "cell_type": "code", "source": "#The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform API\nfrom project_lib import Project\n\nproject = Project(None, '<my_project_id>', '<my_project_token>')\npc = project.project_context\n\n# Show Project, Bucket and Assets\nprint('Project Name: {0}'.format(project.get_name()))\nprint('Project Description: {0}'.format(project.get_description()))\nprint('Project Bucket Name: {0}'.format(project.get_project_bucket_name()))\nprint('Project Assets (Connections): {0}'.format(project.get_assets(asset_type='connection')))\n\n# Save dataframe as csv file in your bucket \nproject.save_data(data=df.to_csv(index=False), file_name='hotel_bookings_v1.csv', overwrite=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "2759fdcf", "cell_type": "markdown", "source": "## Summary \n\nIn this hands-on activity, you have covered the following:\n\n1. Checked the quality of the data.\n2. Conducted data wrangling to ensure datasets were of acceptable quality for use in exploratory data analysis (EDA) and Machine Learning (ML) model development.\n3. Saved the cleansed dataset into a new CSV file."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}