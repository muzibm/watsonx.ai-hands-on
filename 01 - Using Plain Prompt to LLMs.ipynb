{"cells": [{"metadata": {}, "id": "36c33201", "cell_type": "markdown", "source": "## 01 - Using Plain Prompt to LLMs\n- In this notebook, we will send plain prompts directly to Google flan-ul2 model."}, {"metadata": {"scrolled": true}, "id": "1664a584", "cell_type": "code", "source": "# Packages Installation\n!pip install chromadb==0.4.2\n!pip install langchain==0.0.312\n!pip install langchain --upgrade\n!pip install flask-sqlalchemy --user\n!pip install pypdf \n!pip install sentence-transformers", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "id": "4adcdb35", "cell_type": "code", "source": "# Import packages\nimport os\nfrom dotenv import load_dotenv\nfrom time import sleep\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\nfrom langchain import PromptTemplate # Langchain Prompt Template\nfrom langchain.chains import LLMChain, SimpleSequentialChain # Langchain Chains\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.indexes import VectorstoreIndexCreator # Vectorize db index with chromadb\nfrom langchain.embeddings import HuggingFaceEmbeddings # For using HuggingFace embedding models\nfrom langchain.text_splitter import CharacterTextSplitter # Text splitter\n\nprint(\"Done importing dependencies.\")", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "96339420", "cell_type": "code", "source": "# Get our API key and URL from .env\nload_dotenv()\napi_key = \"INSERT YOUR API KEY HERE\"\nibm_cloud_url = \"https://us-south.ml.cloud.ibm.com\"\nproject_id = \"INSERT YOUR PROJECT ID HERE\"\n\nif api_key is None or ibm_cloud_url is None or project_id is None:\n    raise Exception(\"One or more environment variables are missing!\")\nelse:\n    creds = {\n        \"url\": ibm_cloud_url,\n        \"apikey\": api_key \n    }\nprint(\"Done getting env variables.\")", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a51cbd27", "cell_type": "code", "source": "# Initialize the watsonx model\nparams = {\n    GenParams.DECODING_METHOD: \"sample\",\n    GenParams.TEMPERATURE: 0.2,\n    GenParams.TOP_P: 1,\n    GenParams.TOP_K: 25,\n    GenParams.REPETITION_PENALTY: 1.0,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.MAX_NEW_TOKENS: 20\n}\n\nllm_model = Model(\n    model_id=\"google/flan-ul2\",\n    params=params,\n    credentials=creds,\n    project_id=project_id\n)\nprint(\"Done initializing LLM.\")", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "1b25c008", "cell_type": "code", "source": "# Predict with the model\ncountries = [\"France\", \"Japan\", \"Australia\"]\n\ntry:\n  for country in countries:\n    question = f\"What is the capital of {country}\"\n    res = llm_model.generate_text(question)\n    print(f\"The capital of {country} is {res.capitalize()}\")\nexcept Exception as e:\n  print(e)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}